{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOMAB26cgYaTno0MKrDSHfu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#딥러닝 응용 2주차 강의"],"metadata":{"id":"R8Qix_AnjBzi"}},{"cell_type":"markdown","source":["##지난 주 복습<br>\n","스스로 학습이 머신러닝 딥러닝은 추출과 학습을 반복<br>\n","출력 데이터를 보고 입력 데이터를 추측하기 <- 노이즈로부터 본래의 데이터를 얻어낸다<br> 입력에서 노이즈를 추가해서 출력이 같아지는 것은 이해가 가지만 반대의 경우는 가능한가? => Generative AI <br> 정확히는 출력에 남아있는 본래 데이터의 특징을 가지고 입력을 추측하는 것에 가깝다 <br> 차원을 축소하는 이유는 feature를 효과적으로 추출하기 위함 <br> latent variable, latent space -> 압축해서 하나의 점으로 가면 auto encode, 수축하면 최종적으로 gen <br> 교재 집에 놓고왔는데...다음에 들고 와야겠다 <br> 머신러닝 종류 = 지도학습, 비지도학습, 반지도학습 <br> underfitting이 발생하는 이유 = 데이터가 부족해서 충분한 feature를 뽑아내지 못하기 때문<br> overfitting은 반대로 데이터가 많아서 노이즈와 같은 feature를 너무 많이 뽑아내어 효율적인 feature를 구성하지 못했기 때문 <br> 깃허브에 있는 FAQ와 실습 위주로 학습할 것 <br> 챗지피티 결제하는거 까먹었다 <br> cross validation = 교차 검증, test & validation data를 쪼갬으로써 test data의 균질성을 보장하기 위함 => 즉 훈련 데이터와 test data, validation data가 중복되는 것을 피함으로써 모델의 성능을 끌어올리기 위한 수단이다 <br> 특히 데이터의 수가 적은 경우 증감?이라고 하나 데이터를 늘리는 작업을 진행하고 교차검증을 진행하면 효과적이라고 배우긴 했다 <br> 아 맞다 딥러닝 파트 validation data 만드는 거 깜빡했다 나중에 수정할 것<br> softmax -> sigmoid 변경 <br> 종속적인 관계를 끊기 위해 원 핫 인코딩 실시 <br>  "],"metadata":{"id":"dXizLMM7lGtL"}},{"cell_type":"markdown","source":["hyperparameter tunning -> 모델의 성능을 끌어올리기 위해(일반화하기 위해) learning rate,batch size, hidden layer 개수,activation function 등을 조정하는 것 <br> accuracy가 존재하는데 f1 value 그걸 왜 쓰나 -> accuracy는 높지만 데이터가 불균형하여 성능을 제대로 평가하지 못하는 경우가 있다 <br> recall value를 통해 참조하는? 지표로 사용하는 것 같다 <- 좀 더 알아볼 것 (안 배운 부분이라 좀 찾아봐야 할 것 같다)<br> 경사하강법 = 가중치를 최적화하는 과정 <br> learning rate = 가중치를 최적화하는 데 있어 얼마나 크게 이동할지를 조절하는 값 <br> decision tree -> 지니계수(불순도)를 통해 분류한다 (classification도 불순도를 높이는 것이라 말할 수 있다) <br> 클래스가 완전히 분류될 때까지 구역을 나눠가면서 불순도를 높인다 <br> 랜덤 포레스트는 여러 개를 나누는 것 <br>\n","<br>\n","\n","아래와 같이 인코딩 진행\n","1. value conut\n","2. encoding\n","3. value count 후 비교\n","<br>\n","<br>\n","outcome 제외하고 회귀 제외"],"metadata":{"id":"_wM31_Wkv5vR"}}]}