{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPAY+7SDDL3ul6tWVkWKXk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksy3432/ai-class-DL-Application-/blob/main/%5Blecture%5DDLA_week_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 지난 시간 복습\n",
        "* **pretrained model**\n",
        "* 장점) 잘 만든 모델을 default로 사용해서 성능이 좋다\n",
        "* Resnet 등 좋은 모델을 걍 가져다 쓸 수 있다\n",
        "* 모델의 앞 부분은 일반적인 특성을, 뒷 부분은 추상적인(차원이 높은) 특성을 추출\n",
        "*그러므로 앞 부분만 가져다 쓰고 뒤를 튜닝하자\n",
        "*전체 튜닝은 fine_tunning\n",
        "*최초의 w,b는 random"
      ],
      "metadata": {
        "id": "AZU7A-UHvNZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PCA & AE**\n",
        "* AE = 입력과 출력이 같도록 모델을 훈련시킴\n",
        "* 차원축소와 특성 추출을 목적으로 함\n",
        "*  차원을 축소하고, 데이터의 중요한 패턴을 추출하며, 노이즈를 제거  <- 이게 목적\n",
        "*-> latent vector 추출이 목적\n",
        "* AE를 만들면 특정 latent vector를 만들기 때문에 거기에 특화 => 다른 데이터를 집어넣을 경우 이상치 탐지 가능\n",
        "* = 복원 시 reconstruct error가 커진다\n",
        "*encoder가 중요\n"
      ],
      "metadata": {
        "id": "TTY2XD3PzYBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**transformer**\n",
        "* seq2seq모델\n",
        "* encoder 뒤에 lstm,cnn 등을 붙여서 더 깊은 차원의 정보 얻기 가능\n",
        "*transformer의 가장 큰 특징\n",
        "*1.self-attention : 필요한 정보에만 집중하는 것\n",
        "> 구글 번역과 gpt 번역이 차이나는 이유   \n",
        ">1.모델 자체 성능<br>\n",
        ">2.self-attention\n",
        "*2.multi-head attention : self attention을 병렬로 수행 -> feedforward layer\n",
        "*3.embedding : 단어를 밀집된 백터로 표현\n",
        "*4.positional embeddding : 순서 정보 추가"
      ],
      "metadata": {
        "id": "pMtiZIKa3EIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#cnn의 발전\n",
        "* 1.resnet(skip connection)\n",
        "* 2.inception : 서로 다른 필터를 여러 개 사용 -> 1x1 패턴 : 차원 축소. 채널에 다른 패턴\n",
        "* pooling을 하는 이유 : 공간불변성, 데이터 축약\n",
        "* cnn은 모든 채널에 같은 필터, senet은 채널에 따라 다른 필터 -> 채널의 중요도를 다르게 둔다(이건 depthwise) senet은 그냥 중요도를 다르게 두는 것만 해당\n",
        "* depwise convolution으로 처리된 출력은 pointwise convolution을 통해 합쳐진다\n",
        "*xception = 채널별로 다른 필터 사용\n"
      ],
      "metadata": {
        "id": "7hJZUekj3X60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "attention 구현"
      ],
      "metadata": {
        "id": "ArKpO93FEyz2"
      }
    }
  ]
}