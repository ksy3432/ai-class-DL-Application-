{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOFfWJjITDD9nzCS21A7cY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksy3432/ai-class-DL-Application-/blob/main/%5BLecture%5DDLA_week_5ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "sa9SgwyBs7lM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* transformer <- 이전 모델의 한계와 극복을 위해 고안됨\n",
        "* 자연어 =  sequential 데이터(순서가 중요) => 입력이 길어지면 gradient vanishing 문제 발생\n",
        "* rnn,lstm 등이 대표적 모델\n",
        "*sequence to sequence(seq2seq) -> encoder,decoder,attention(선택 사항)으로 구성됨\n",
        "* self-attention ->  시퀀스 내에서 각 요소(단어, 토큰 등)가 자신을 포함한 다른 모든 요소들과의 관계를 계산하는 방식\n",
        "*각 요소에 대한 3가지 백터( key,query,value)를 계산하여 각 요소의 가중치 조정\n",
        "* multi-head-context\n",
        "*attention = 입력값 중 어떤 것이 중요한 지를 판단\n",
        "* 교수님 깃헙의 cnn-variation 참조하기\n",
        "* CNN에서 각 채널의 중요도가 다름 -> 더 중요한 채널에 집중하는 것이 효율적\n",
        "* attention, multihead-attention,embedding,positional embedding\n",
        "* self-attention은 본인이 알아서 비교하는 것"
      ],
      "metadata": {
        "id": "pXBZlq9QtHaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoEncoder\n",
        "* multi-layer perception 기존 fcnn 모델 등이 해당됨 hidden layer 등을 거치면서 학습됨 출력의 형식이 정해져있음 input과 output의 품질이 차이가 남 (represented x)\n",
        "*단점 : 잠재공간의 문제(배운 잠재공간의 해석 문제, 학습된 잠재 공간의 연속성 문제, 생성된 데이터의 품질 문제) =>이를 해결하기 위해 나온 것이 VAE(variation autoencoder)\n",
        "*기존의 AE는 잠재 공간을 점으로 해석,VAE는 일종의 공간? 해석하기 쉬운 영역으로 간주(예를 들어 가우시안 분포 등)\n",
        "*그 잠재공간을 무작위적으로 샘플링하여 다음 출력을 생성하는데 이 '샘플링' 과정에서 문제가 생김 -> 재파라미터화 트릭 사용\n",
        "*VAE의 손실함수 : 재구성 손실(reconstruction loss), 잠재 공간 정규화 손실(latent space regularization loss) 등\n",
        "* Reconstruction loss = 결과 와 원본의 차이를 구하는 손실 함수, 데이터의 특성에 따라 Mse(회귀),binary_crossentropy(이진 분류) 등을 사용\n",
        "* Latent space regularization loss <- KL Divergence(KL 발상에 속해 있음) : VAE가 학습하는 잠재분포와 정규분포와의 차이 측정 및 정규분포를 따르도록 학습\n",
        "* autoencoder = 모델의 입력과 출력이 최대한 비슷하게 만드는 것\n",
        "* rare_event = 희소 클래스로 인한 데이터 불균형 -> autoencoder로 해결 가능\n",
        "* application\n",
        "*encoder와 decoder가 둘 다 있지만 encoder는 붙어있을 뿐 decoder가 메인\n",
        "* 개념과 구조가 단순한 것이 특징\n",
        "*오토인코더 키워드 : latent vector (latent space), reconstruct error\n",
        "* reconstruction error => 같은 모델에서 입력 데이터를 압축한 후 다시 복원할 때, 입력과 출력 간의 차이를 측정하는 값\n",
        "*latnet error => 입력 데이터를 인코딩할 때 만들어지는 저차원 표현 또는 잠재 공간 표현\n",
        "* 당뇨병을 이용한 pca 예제 -> 본래의 차원(8)을 2개의 차원으로 축소\n",
        "*latent vector를 얻는 것이 정말 중요함! => 뭔가 특징을 나타내는 변수이기 때문(가진 많은 feature 중 중요한 것을 나타내는 최소한의 feature)\n",
        "*ae_credit 참조\n",
        "*autoencoder 만들고 데이터 섞어서 응용 실습\n",
        "정리하자면"
      ],
      "metadata": {
        "id": "JOIuzGChtHe-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PnjLU-UXF-HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#image segmentation\n",
        "* 이미지를 여러 영역으로 나누는 작업\n",
        "* 이미지 내의 각 픽셀을 특정 클래스로 분류\n",
        "* 이미지의 각 부분이 어느 클래스에 속하는지 정확히 아는 것이 목적\n",
        "* Semantic Segmentation (의미적 분할) -> 같은 클래스 내에서도 서로 다른 개체(인스턴스)를 구분\n",
        "* Mask-based Classification ->  객체에 대해 고유한 마스크를 생성하여, 객체의 픽셀 단위 경계를 정확하게 분리하고 분류\n",
        "* mask-transformer =>  이미지 내의 마스크를 예측하고, 이 마스크를 기반으로 각 객체나 영역을 분류\n",
        "* segment anything -> 최첨단 범용 이미지 세분화 모델로, 어떤 이미지든 빠르고 쉽게 세분화할 수 있는 기술\n",
        "*unet -> 이미지 세분화(Image Segmentation)에 널리 사용되는 딥러닝 모델, 인코더-디코더 구조를 기반으로 하며, 픽셀 단위로 이미지를 분류하는 작업에서 뛰어난 성능을 보임\n",
        "*unet이 시험에 나오지는 않음\n"
      ],
      "metadata": {
        "id": "XMJVlPEttHhS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezp5nCzns65M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YZyR8ZO0tHjP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gyJkHPdytIoi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}